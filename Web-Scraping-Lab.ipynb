{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:center\">\n",
    "    <a href=\"https://skills.network/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01\" target=\"_blank\">\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/assets/logos/SN_web_lightmode.png\" width=\"200\" alt=\"Skills Network Logo\"  />\n",
    "    </a>\n",
    "</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Hands-on Lab : Web Scraping**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimated time needed: **30 to 45** minutes\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objectives\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this lab you will perform the following:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Extract information from a given web site \n",
    "* Write the scraped data into a csv file.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract information from the given web site\n",
    "You will extract the data from the below web siteu w: <br> \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this url contains the data you need to scrape\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data you need to scrape is the **name of the programming language** and **average annual salary**.<br> It is a good idea to open the url in your web broswer and study the contents of the web page before you start to scrape.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the required libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.29.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "headers, data = extract_programming_languages_data(url)\n",
    "\n",
    "if headers and data:\n",
    "    print(\"Headers:\", headers)\n",
    "    for row in data:\n",
    "        print(row)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the webpage at the url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Webpage downloaded and saved as 'Programming_Languages.html'.\n"
     ]
    }
   ],
   "source": [
    "#your code goes heimport requests\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "def download_webpage(url, filename):\n",
    "    # Send a GET request to the URL\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    # Check if the request was successful\n",
    "    if response.status_code == 200:\n",
    "        # Write the content to a file\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Webpage downloaded and saved as '{filename}'.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "filename = \"Programming_Languages.html\"\n",
    "download_webpage(url, filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a soup object\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#your code goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scrape the `Language name` and `annual average salary`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: lxml in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.9.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   Salary survey results of programming languages\n",
      "  </title>\n",
      "  <style>\n",
      "   table, th, td {\n",
      "  border: 1px solid black;\n",
      "}\n",
      "  </style>\n",
      " </head>\n",
      " <body>\n",
      "  <hr/>\n",
      "  <h2>\n",
      "   Popular Programming Languages\n",
      "  </h2>\n",
      "  <hr/>\n",
      "  <p>\n",
      "   Finding out which is the best language is a tough task. A programming language is created to solve a specific problem. A language which is good for task A may not be able to properly handle task B. Comparing programming language is never easy. What we can do, however, is find which is popular in the industry.\n",
      "  </p>\n",
      "  <p>\n",
      "   There are many ways to find the popularity of a programming languages. Counting the number of google searchs for each language is a simple way to find the popularity. GitHub and StackOverflow also can give some good pointers.\n",
      "  </p>\n",
      "  <p>\n",
      "   Salary surveys are a way to find out the programmings languages that are most in demand in the industry. Below table is the result of one such survey. When using any survey keep in mind that the results vary year on year.\n",
      "  </p>\n",
      "  <hr/>\n",
      "  <table>\n",
      "   <tbody>\n",
      "    <tr>\n",
      "     <td>\n",
      "      No.\n",
      "     </td>\n",
      "     <td>\n",
      "      Language\n",
      "     </td>\n",
      "     <td>\n",
      "      Created By\n",
      "     </td>\n",
      "     <td>\n",
      "      Average Annual Salary\n",
      "     </td>\n",
      "     <td>\n",
      "      Learning Difficulty\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      1\n",
      "     </td>\n",
      "     <td>\n",
      "      Python\n",
      "     </td>\n",
      "     <td>\n",
      "      Guido van Rossum\n",
      "     </td>\n",
      "     <td>\n",
      "      $114,383\n",
      "     </td>\n",
      "     <td>\n",
      "      Easy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      2\n",
      "     </td>\n",
      "     <td>\n",
      "      Java\n",
      "     </td>\n",
      "     <td>\n",
      "      James Gosling\n",
      "     </td>\n",
      "     <td>\n",
      "      $101,013\n",
      "     </td>\n",
      "     <td>\n",
      "      Easy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      3\n",
      "     </td>\n",
      "     <td>\n",
      "      R\n",
      "     </td>\n",
      "     <td>\n",
      "      Robert Gentleman, Ross Ihaka\n",
      "     </td>\n",
      "     <td>\n",
      "      $92,037\n",
      "     </td>\n",
      "     <td>\n",
      "      Hard\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      4\n",
      "     </td>\n",
      "     <td>\n",
      "      Javascript\n",
      "     </td>\n",
      "     <td>\n",
      "      Netscape\n",
      "     </td>\n",
      "     <td>\n",
      "      $110,981\n",
      "     </td>\n",
      "     <td>\n",
      "      Easy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      5\n",
      "     </td>\n",
      "     <td>\n",
      "      Swift\n",
      "     </td>\n",
      "     <td>\n",
      "      Apple\n",
      "     </td>\n",
      "     <td>\n",
      "      $130,801\n",
      "     </td>\n",
      "     <td>\n",
      "      Easy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      6\n",
      "     </td>\n",
      "     <td>\n",
      "      C++\n",
      "     </td>\n",
      "     <td>\n",
      "      Bjarne Stroustrup\n",
      "     </td>\n",
      "     <td>\n",
      "      $113,865\n",
      "     </td>\n",
      "     <td>\n",
      "      Hard\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      7\n",
      "     </td>\n",
      "     <td>\n",
      "      C#\n",
      "     </td>\n",
      "     <td>\n",
      "      Microsoft\n",
      "     </td>\n",
      "     <td>\n",
      "      $88,726\n",
      "     </td>\n",
      "     <td>\n",
      "      Hard\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      8\n",
      "     </td>\n",
      "     <td>\n",
      "      PHP\n",
      "     </td>\n",
      "     <td>\n",
      "      Rasmus Lerdorf\n",
      "     </td>\n",
      "     <td>\n",
      "      $84,727\n",
      "     </td>\n",
      "     <td>\n",
      "      Easy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      9\n",
      "     </td>\n",
      "     <td>\n",
      "      SQL\n",
      "     </td>\n",
      "     <td>\n",
      "      Donald D. Chamberlin, Raymond F. Boyce.\n",
      "     </td>\n",
      "     <td>\n",
      "      $84,793\n",
      "     </td>\n",
      "     <td>\n",
      "      Easy\n",
      "     </td>\n",
      "    </tr>\n",
      "    <tr>\n",
      "     <td>\n",
      "      10\n",
      "     </td>\n",
      "     <td>\n",
      "      Go\n",
      "     </td>\n",
      "     <td>\n",
      "      Robert Griesemer, Ken Thompson, Rob Pike.\n",
      "     </td>\n",
      "     <td>\n",
      "      $94,082\n",
      "     </td>\n",
      "     <td>\n",
      "      Difficult\n",
      "     </td>\n",
      "    </tr>\n",
      "   </tbody>\n",
      "  </table>\n",
      "  <hr/>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4 lxml\n",
    "from bs4 import BeautifulSoup\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "\n",
    "def create_soup_from_file(filename):\n",
    "    # Open the HTML file\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        # Read the content of the file\n",
    "        html_content = file.read()\n",
    "    \n",
    "    # Create a BeautifulSoup object\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')  # or 'lxml'\n",
    "    \n",
    "    return soup\n",
    "\n",
    "# Example usage\n",
    "filename = \"Programming_Languages.html\"  # The HTML file you saved earlier\n",
    "soup = create_soup_from_file(filename)\n",
    "\n",
    "# Print the soup object (or a portion of it)\n",
    "print(soup.prettify())  # This prints the HTML in a more readable format\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the scrapped data into a file named *popular-languages.csv*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (2.29.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (4.11.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (3.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (1.26.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests) (2023.5.7)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from beautifulsoup4) (2.3.2.post1)\n",
      "Webpage downloaded and saved as 'Programming_Languages.html'.\n",
      "Data saved to 'popular-languages.csv'.\n"
     ]
    }
   ],
   "source": [
    "!pip install requests beautifulsoup4\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "def download_webpage(url, filename):\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        with open(filename, 'w', encoding='utf-8') as file:\n",
    "            file.write(response.text)\n",
    "        print(f\"Webpage downloaded and saved as '{filename}'.\")\n",
    "    else:\n",
    "        print(f\"Error: {response.status_code}\")\n",
    "\n",
    "def create_soup_from_file(filename):\n",
    "    with open(filename, 'r', encoding='utf-8') as file:\n",
    "        html_content = file.read()\n",
    "    return BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "def save_data_to_csv(soup, csv_filename):\n",
    "    # Find the table in the soup object\n",
    "    table = soup.find('table')\n",
    "    \n",
    "    # Extract headers\n",
    "    headers = [header.text for header in table.find_all('th')]\n",
    "    \n",
    "    # Extract rows\n",
    "    rows = []\n",
    "    for row in table.find_all('tr')[1:]:  # Skip the header row\n",
    "        cells = row.find_all('td')\n",
    "        rows.append([cell.text for cell in cells])\n",
    "    \n",
    "    # Write to CSV file\n",
    "    with open(csv_filename, 'w', newline='', encoding='utf-8') as csv_file:\n",
    "        writer = csv.writer(csv_file)\n",
    "        writer.writerow(headers)  # Write the headers\n",
    "        writer.writerows(rows)     # Write the data rows\n",
    "    \n",
    "    print(f\"Data saved to '{csv_filename}'.\")\n",
    "\n",
    "# Example usage\n",
    "url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBM-DA0321EN-SkillsNetwork/labs/datasets/Programming_Languages.html\"\n",
    "html_filename = \"Programming_Languages.html\"\n",
    "csv_filename = \"popular-languages.csv\"\n",
    "\n",
    "# Download the webpage\n",
    "download_webpage(url, html_filename)\n",
    "\n",
    "# Create a soup object from the downloaded HTML file\n",
    "soup = create_soup_from_file(html_filename)\n",
    "\n",
    "# Save the scraped data into a CSV file\n",
    "save_data_to_csv(soup, csv_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Authors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ramesh Sannareddy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other Contributors\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rav Ahuja\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |\n",
    "|---|---|---|---|\n",
    "| 2020-10-17  | 0.1  | Ramesh Sannareddy  |  Created initial version of the lab |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Copyright &copy; 2020 IBM Corporation. This notebook and its source code are released under the terms of the [MIT License](https://cognitiveclass.ai/mit-license/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDA0321ENSkillsNetwork928-2022-01-01).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
